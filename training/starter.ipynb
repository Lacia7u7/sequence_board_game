{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Starter: Sequence RL — debug-friendly notebook (Anaconda base)\n",
    "\n",
    "Run the cells **in order** (1 → 10).\n",
    "This notebook:\n",
    "- uses your Anaconda base env (no venv),\n",
    "- verifies CUDA,\n",
    "- wires `sys.path` so `training/` imports,\n",
    "- runs the trainer **in-process** (easy to debug) or via subprocess,\n",
    "- starts TensorBoard,\n",
    "- evaluates a saved policy,\n",
    "- and gives quick unit-test & step-debug helpers.\n"
   ],
   "id": "c496235011770648"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T19:22:58.866390Z",
     "start_time": "2025-08-24T19:22:58.579768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, sys, subprocess, textwrap\n",
    "\n",
    "print(\"Python:\", sys.executable)\n",
    "try:\n",
    "    import torch\n",
    "    print(\"PyTorch:\", torch.__version__)\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    print(\"CUDA version:\", getattr(torch.version, \"cuda\", None))\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "        print(\"Device 0:\", torch.cuda.get_device_name(0))\n",
    "except Exception as e:\n",
    "    print(\"Torch import error:\", e)\n",
    "\n",
    "# Optional: show nvidia-smi (won't crash if missing)\n",
    "try:\n",
    "    print(\"\\n--- nvidia-smi ---\")\n",
    "    out = subprocess.run([\"nvidia-smi\"], capture_output=True, text=True)\n",
    "    print(out.stdout or out.stderr)\n",
    "except Exception as e:\n",
    "    print(\"nvidia-smi not available:\", e)\n"
   ],
   "id": "a41da3316c0ab59a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: C:\\Users\\carlo\\anaconda3\\python.exe\n",
      "PyTorch: 2.2.1\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "CUDA device count: 1\n",
      "Device 0: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "\n",
      "--- nvidia-smi ---\n",
      "Sun Aug 24 13:22:58 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 551.61                 Driver Version: 551.61         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   57C    P8              4W /   25W |     276MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      6032    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     12208    C+G   ...ZWMJ2QHF7EXQJXRPE6GR5GOTQ\\DeepL.exe      N/A      |\n",
      "|    0   N/A  N/A     19980    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A     31236    C+G   ...n\\139.0.3405.102\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     32760    C+G   ...by Google One\\1.9.0.6\\googleone.exe      N/A      |\n",
      "|    0   N/A  N/A     36284    C+G   ...n\\139.0.3405.102\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     38804    C+G   ...cw5n1h2txyewy\\CrossDeviceResume.exe      N/A      |\n",
      "|    0   N/A  N/A     40520    C+G   ...3.0_x64__cv1g1gvanyjgm\\WhatsApp.exe      N/A      |\n",
      "|    0   N/A  N/A     41608    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     42704    C+G   ...m 2025.2.0.1\\jbr\\bin\\cef_server.exe      N/A      |\n",
      "|    0   N/A  N/A     50512    C+G   ...3\\extracted\\runtime\\WeChatAppEx.exe      N/A      |\n",
      "|    0   N/A  N/A     59120    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     59948    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     61132    C+G   ...n\\139.0.3405.102\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     61472    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     61892    C+G   ...Desktop\\app-3.5.2\\GitHubDesktop.exe      N/A      |\n",
      "|    0   N/A  N/A     65220    C+G   ...n\\139.0.3405.111\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     67228    C+G   C:\\Windows\\System32\\ShellHost.exe           N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T19:22:59.878896Z",
     "start_time": "2025-08-24T19:22:59.720866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, sys, importlib, json, pathlib\n",
    "\n",
    "# If this notebook is inside training/, repo_root = parent; otherwise set it manually.\n",
    "cwd = os.getcwd()\n",
    "repo_root = os.path.abspath(os.path.join(cwd, \"..\")) if os.path.basename(cwd).lower()==\"training\" else cwd\n",
    "training_pkg_dir = os.path.join(repo_root, \"training\")\n",
    "\n",
    "print(\"CWD:\", cwd)\n",
    "print(\"Repo root:\", repo_root)\n",
    "print(\"Training package dir exists:\", os.path.isdir(training_pkg_dir))\n",
    "\n",
    "# Ensure repo root is on sys.path so \"import training\" resolves to local sources\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "\n",
    "# Sanity: import training\n",
    "try:\n",
    "    import training\n",
    "    print(\"training import OK from:\", training.__file__)\n",
    "except Exception as e:\n",
    "    print(\"training import failed:\", e)\n",
    "    raise\n",
    "\n",
    "# Config paths\n",
    "tiny_cfg = os.path.join(training_pkg_dir, \"configs\", \"tiny-smoke.json\")\n",
    "default_cfg = os.path.join(training_pkg_dir, \"configs\", \"default.json\")\n",
    "print(\"tiny-smoke.json exists?\", os.path.exists(tiny_cfg))\n",
    "print(\"default.json exists?\", os.path.exists(default_cfg))\n"
   ],
   "id": "d58f873f4bf64e5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: E:\\sequence_game_board\\sequence_board_game\\training\n",
      "Repo root: E:\\sequence_game_board\\sequence_board_game\n",
      "Training package dir exists: True\n",
      "training import OK from: E:\\sequence_game_board\\sequence_board_game\\training\\__init__.py\n",
      "tiny-smoke.json exists? True\n",
      "default.json exists? True\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T19:23:01.329594Z",
     "start_time": "2025-08-24T19:23:01.076295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Auto-reload edited modules without restarting the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import io, contextlib, runpy, time, shlex, subprocess\n",
    "from typing import Dict, Any\n",
    "\n",
    "def pretty(o):\n",
    "    import pprint; pprint.pp(o, width=100)\n",
    "\n",
    "def apply_overrides(cfg: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Dot-path override into nested dict.\"\"\"\n",
    "    out = json.loads(json.dumps(cfg))\n",
    "    for k, v in override.items():\n",
    "        node = out\n",
    "        parts = k.split(\".\")\n",
    "        for p in parts[:-1]:\n",
    "            if p not in node or not isinstance(node[p], dict):\n",
    "                node[p] = {}\n",
    "            node = node[p]\n",
    "        node[parts[-1]] = v\n",
    "    return out\n",
    "\n",
    "def load_cfg(path: str) -> Dict[str, Any]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def write_cfg(path: str, cfg: Dict[str, Any]) -> None:\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(cfg, f, indent=2)\n",
    "\n",
    "print(\"Helpers ready.\")\n"
   ],
   "id": "ea2478cd6fd4ae9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Helpers ready.\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T19:23:03.831717Z",
     "start_time": "2025-08-24T19:23:03.660548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pick a base config\n",
    "CFG_PATH = tiny_cfg  # change to default_cfg for bigger runs\n",
    "\n",
    "# Build an override suited to a laptop GPU. If CUDA is False, we force CPU in override.\n",
    "import torch\n",
    "OVERRIDE = {\n",
    "    \"training.num_envs\": 8,\n",
    "    \"training.rollout_length\": 32,\n",
    "    \"training.total_updates\": 5,       # bump later for longer runs\n",
    "    \"training.minibatch_size\": 512,\n",
    "}\n",
    "if not torch.cuda.is_available():\n",
    "    OVERRIDE[\"training.use_cuda\"] = False\n",
    "\n",
    "print(\"Config:\", CFG_PATH)\n",
    "print(\"Overrides:\")\n",
    "pretty(OVERRIDE)\n",
    "\n",
    "# Preview the merged config (not persisted)\n",
    "merged_preview = apply_overrides(load_cfg(CFG_PATH), OVERRIDE)\n",
    "pretty({k: merged_preview[k] for k in [\"training\",\"model\",\"logging\"] if k in merged_preview})\n"
   ],
   "id": "ac37287815caf0ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: E:\\sequence_game_board\\sequence_board_game\\training\\configs\\tiny-smoke.json\n",
      "Overrides:\n",
      "{'training.num_envs': 8,\n",
      " 'training.rollout_length': 32,\n",
      " 'training.total_updates': 5,\n",
      " 'training.minibatch_size': 512}\n",
      "{'training': {'algorithm': 'ppo_lstm',\n",
      "              'seed': 42,\n",
      "              'num_envs': 8,\n",
      "              'rollout_length': 32,\n",
      "              'total_updates': 5,\n",
      "              'gamma': 0.99,\n",
      "              'gae_lambda': 0.95,\n",
      "              'lr': 0.001,\n",
      "              'clip_eps': 0.2,\n",
      "              'entropy_coef': 0.01,\n",
      "              'value_coef': 0.5,\n",
      "              'max_grad_norm': 0.5,\n",
      "              'amp': False,\n",
      "              'opponent_pool': {'current': 1.0, 'snapshots': 0.0, 'heuristics': 0.0},\n",
      "              'episode_cap': 200,\n",
      "              'minibatch_size': 512},\n",
      " 'model': {'conv_channels': [32, 32, 64], 'lstm_hidden': 128, 'lstm_layers': 1},\n",
      " 'logging': {'tensorboard': False,\n",
      "             'csv': True,\n",
      "             'jsonl': False,\n",
      "             'log_private_hands_locally': False,\n",
      "             'logdir': 'runs/smoke'}}\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T19:32:25.916994Z",
     "start_time": "2025-08-24T19:32:25.775342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys, os, runpy, contextlib, io\n",
    "\n",
    "# Compose argv exactly like the CLI would\n",
    "argv = [\n",
    "    \"training.scripts.train\",\n",
    "    \"--config\", CFG_PATH,\n",
    "    \"--override\", json.dumps(OVERRIDE),\n",
    "]\n",
    "\n",
    "# Capture stdout/stderr so the cell prints a clean, bounded block.\n",
    "stdout_buf, stderr_buf = io.StringIO(), io.StringIO()\n",
    "print(\"Running in-process with argv:\", argv)\n",
    "\n",
    "with contextlib.redirect_stdout(stdout_buf), contextlib.redirect_stderr(stderr_buf):\n",
    "    try:\n",
    "        # Make sys.argv visible to the module's argparse\n",
    "        old_argv = sys.argv\n",
    "        sys.argv = argv\n",
    "        # Auto-reload ensures your edits to modules are picked up before run\n",
    "        result = runpy.run_module(\"training.scripts.train\", run_name=\"__main__\")\n",
    "        exit_code = 0\n",
    "    except SystemExit as se:\n",
    "        # argparse may call sys.exit(); capture its code\n",
    "        exit_code = int(getattr(se, \"code\", 0) or 0)\n",
    "    except Exception as e:\n",
    "        exit_code = 1\n",
    "        print(\"EXCEPTION:\", repr(e))\n",
    "    finally:\n",
    "        sys.argv = old_argv\n",
    "\n",
    "out, err = stdout_buf.getvalue(), stderr_buf.getvalue()\n",
    "print(\"--- STDOUT ---\\n\", out[-10000:])   # last 10k chars\n",
    "print(\"--- STDERR ---\\n\", err[-10000:])\n",
    "print(\"Exit code:\", exit_code)\n",
    "\n",
    "# If you crashed and want to inspect the last exception, run:\n",
    "# %debug\n"
   ],
   "id": "8228756e6c62d23b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in-process with argv: ['training.scripts.train', '--config', 'E:\\\\sequence_game_board\\\\sequence_board_game\\\\training\\\\configs\\\\tiny-smoke.json', '--override', '{\"training.num_envs\": 8, \"training.rollout_length\": 32, \"training.total_updates\": 5, \"training.minibatch_size\": 512}']\n",
      "--- STDOUT ---\n",
      " EXCEPTION: AttributeError(\"'GameState' object has no attribute 'sequences_meta_cells'\")\n",
      "\n",
      "--- STDERR ---\n",
      " \n",
      "Exit code: 1\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T19:24:06.393797Z",
     "start_time": "2025-08-24T19:24:06.252715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inline (Jupyter) TensorBoard. If it fails, use the external command below.\n",
    "%load_ext tensorboard\n",
    "import os\n",
    "logdir = os.path.join(repo_root, \"runs\")\n",
    "print(\"TensorBoard logdir:\", logdir)\n",
    "%tensorboard --logdir $logdir --port 6006\n"
   ],
   "id": "f4bc5b520eb350e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "TensorBoard logdir: E:\\sequence_game_board\\sequence_board_game\\runs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 36372), started 0:02:08 ago. (Use '!kill 36372' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-64219217080aa792\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-64219217080aa792\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f9ed2e2331a031ed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
