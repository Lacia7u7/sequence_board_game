{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Starter: Sequence RL — debug-friendly notebook (Anaconda base)\n",
    "\n",
    "Run the cells **in order** (1 → 10).\n",
    "This notebook:\n",
    "- uses your Anaconda base env (no venv),\n",
    "- verifies CUDA,\n",
    "- wires `sys.path` so `training/` imports,\n",
    "- runs the trainer **in-process** (easy to debug) or via subprocess,\n",
    "- starts TensorBoard,\n",
    "- evaluates a saved policy,\n",
    "- and gives quick unit-test & step-debug helpers.\n"
   ],
   "id": "c496235011770648"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T18:27:43.325754Z",
     "start_time": "2025-08-29T18:27:38.534693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, sys, subprocess, textwrap\n",
    "\n",
    "print(\"Python:\", sys.executable)\n",
    "try:\n",
    "    import torch\n",
    "    print(\"PyTorch:\", torch.__version__)\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    print(\"CUDA version:\", getattr(torch.version, \"cuda\", None))\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "        print(\"Device 0:\", torch.cuda.get_device_name(0))\n",
    "except Exception as e:\n",
    "    print(\"Torch import error:\", e)\n",
    "\n",
    "# Optional: show nvidia-smi (won't crash if missing)\n",
    "try:\n",
    "    print(\"\\n--- nvidia-smi ---\")\n",
    "    out = subprocess.run([\"nvidia-smi\"], capture_output=True, text=True)\n",
    "    print(out.stdout or out.stderr)\n",
    "except Exception as e:\n",
    "    print(\"nvidia-smi not available:\", e)\n"
   ],
   "id": "a41da3316c0ab59a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: C:\\Users\\carlo\\anaconda3\\python.exe\n",
      "PyTorch: 2.2.1\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "CUDA device count: 1\n",
      "Device 0: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "\n",
      "--- nvidia-smi ---\n",
      "Fri Aug 29 12:27:43 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 551.61                 Driver Version: 551.61         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   58C    P8              4W /   25W |     186MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     10532      C   C:\\Users\\carlo\\anaconda3\\python.exe         N/A      |\n",
      "|    0   N/A  N/A     11236    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     12716    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     12848    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     15964    C+G   ...n\\139.0.3405.111\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     16604    C+G   C:\\Windows\\System32\\ShellHost.exe           N/A      |\n",
      "|    0   N/A  N/A     17364    C+G   ...Desktop\\app-3.5.2\\GitHubDesktop.exe      N/A      |\n",
      "|    0   N/A  N/A     18064    C+G   ...m 2025.2.0.1\\jbr\\bin\\cef_server.exe      N/A      |\n",
      "|    0   N/A  N/A     20116    C+G   ...ZWMJ2QHF7EXQJXRPE6GR5GOTQ\\DeepL.exe      N/A      |\n",
      "|    0   N/A  N/A     20820    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     21300    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     21608    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     22908    C+G   ...n\\139.0.3405.111\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     22916    C+G   ...64__8wekyb3d8bbwe\\CalculatorApp.exe      N/A      |\n",
      "|    0   N/A  N/A     23036    C+G   ...by Google One\\1.9.0.6\\googleone.exe      N/A      |\n",
      "|    0   N/A  N/A     24032    C+G   ...3.0_x64__cv1g1gvanyjgm\\WhatsApp.exe      N/A      |\n",
      "|    0   N/A  N/A     24472    C+G   ...n\\139.0.3405.119\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     39920    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T05:17:58.461437Z",
     "start_time": "2025-09-04T05:17:16.527874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ✅ Run training.scripts.train in-process with a merged temp config,\n",
    "#    showing output LIVE in the PyCharm console while debugging.\n",
    "\n",
    "import os, sys, runpy, importlib, json, time\n",
    "\n",
    "# --- configure your base config and overrides (dot-paths supported) ---\n",
    "CFG_PATH = r\"E:\\sequence_game_board\\sequence_board_game\\training\\configs\\full-tiny-smoke.json\"\n",
    "OVERRIDE = {\n",
    "    \"training.total_updates\": 20\n",
    "}\n",
    "\n",
    "# --- helpers: load cfg, apply dot-path overrides, write temp cfg ---\n",
    "def load_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def apply_overrides(cfg: dict, overrides: dict) -> dict:\n",
    "    out = json.loads(json.dumps(cfg))  # deep copy\n",
    "    for k, v in overrides.items():\n",
    "        cur = out\n",
    "        parts = k.split(\".\")\n",
    "        for p in parts[:-1]:\n",
    "            if p not in cur or not isinstance(cur[p], dict):\n",
    "                cur[p] = {}\n",
    "            cur = cur[p]\n",
    "        cur[parts[-1]] = v\n",
    "    return out\n",
    "\n",
    "# --- compute repo root (parent of 'training' folder) and ensure import path ---\n",
    "# CFG_PATH .../training/configs/xxx.json  -> go up two levels to repo root\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname(CFG_PATH), os.pardir, os.pardir))\n",
    "print(\"Project root:\", project_root)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# --- purge any cached 'training' modules so edits are picked up ---\n",
    "to_purge = [m for m in list(sys.modules) if m == \"training\" or m.startswith(\"training.\")]\n",
    "for m in to_purge:\n",
    "    sys.modules.pop(m, None)\n",
    "importlib.invalidate_caches()\n",
    "\n",
    "# --- build merged temp config ---\n",
    "base_cfg = load_json(CFG_PATH)\n",
    "merged_cfg = apply_overrides(base_cfg, OVERRIDE)\n",
    "\n",
    "cfg_dir = os.path.dirname(CFG_PATH)\n",
    "runtime_cfg_path = os.path.join(cfg_dir, f\"_runtime_{int(time.time())}.json\")\n",
    "with open(runtime_cfg_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(merged_cfg, f, indent=2)\n",
    "print(\"Merged config written to:\", runtime_cfg_path)\n",
    "print(\"total_updates =\", merged_cfg.get(\"training\", {}).get(\"total_updates\"))\n",
    "\n",
    "# --- (optional) encourage line-buffered output in some environments ---\n",
    "try:\n",
    "    sys.stdout.reconfigure(line_buffering=True)  # Python 3.7+\n",
    "    sys.stderr.reconfigure(line_buffering=True)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# --- run the train module in-process with the merged config (no redirection) ---\n",
    "argv = [\"training.scripts.train\", \"--config\", runtime_cfg_path]\n",
    "print(\"Running in-process with argv:\", argv)\n",
    "\n",
    "old_argv = list(sys.argv)\n",
    "exit_code = 0\n",
    "try:\n",
    "    sys.argv = argv\n",
    "    # All prints from training.scripts.train will appear LIVE in PyCharm's console\n",
    "    runpy.run_module(\"training.scripts.train\", run_name=\"__main__\", alter_sys=True)\n",
    "except SystemExit as se:\n",
    "    exit_code = int(getattr(se, \"code\", 0) or 0)\n",
    "except Exception as e:\n",
    "    # Any exception prints directly to the console\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    exit_code = 1\n",
    "finally:\n",
    "    sys.argv = old_argv\n",
    "\n",
    "print(\"Exit code:\", exit_code)\n",
    "\n",
    "# (Optional) clean up the temp config file\n",
    "try:\n",
    "    os.remove(runtime_cfg_path)\n",
    "except Exception:\n",
    "    pass\n"
   ],
   "id": "8228756e6c62d23b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: E:\\sequence_game_board\\sequence_board_game\n",
      "Merged config written to: E:\\sequence_game_board\\sequence_board_game\\training\\configs\\_runtime_1756963036.json\n",
      "total_updates = 20\n",
      "Running in-process with argv: ['training.scripts.train+', '--config', 'E:\\\\sequence_game_board\\\\sequence_board_game\\\\training\\\\configs\\\\_runtime_1756963036.json']\n",
      "Exit code: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_7572\\2210071981.py\", line 69, in <module>\n",
      "    runpy.run_module(\"training.scripts.train_vec\", run_name=\"__main__\", alter_sys=True)\n",
      "  File \"<frozen runpy>\", line 226, in run_module\n",
      "  File \"<frozen runpy>\", line 98, in _run_module_code\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"E:\\sequence_game_board\\sequence_board_game\\training\\scripts\\train_vec.py\", line 534, in <module>\n",
      "    main()\n",
      "  File \"E:\\sequence_game_board\\sequence_board_game\\training\\scripts\\train_vec.py\", line 207, in main\n",
      "    vecenv = SubprocVecEnv(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"E:\\sequence_game_board\\sequence_board_game\\training\\envs\\vectorized\\subproc_vec_env.py\", line 259, in __init__\n",
      "    obs0, info0 = self._reset_one(0, seed=base_seed)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\sequence_game_board\\sequence_board_game\\training\\envs\\vectorized\\subproc_vec_env.py\", line 284, in _reset_one\n",
      "    self._parents[idx].send((_CMD_RESET, {\"seed\": seed}))\n",
      "  File \"C:\\Users\\carlo\\anaconda3\\Lib\\multiprocessing\\connection.py\", line 205, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"C:\\Users\\carlo\\anaconda3\\Lib\\multiprocessing\\connection.py\", line 279, in _send_bytes\n",
      "    ov, err = _winapi.WriteFile(self._handle, buf, overlapped=True)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [WinError 232] The pipe is being closed\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##EVAL",
   "id": "12f6081fa35b34f6"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-04T06:25:39.328474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ✅ Run training.scripts.train in-process with a merged temp config,\n",
    "#    showing output LIVE in the PyCharm console while debugging.\n",
    "\n",
    "import os, sys, runpy, importlib, json, time\n",
    "\n",
    "# --- configure your base config and overrides (dot-paths supported) ---\n",
    "CFG_PATH = r\"E:\\sequence_game_board\\sequence_board_game\\training\\configs\\full-tiny-smoke.json\"\n",
    "OVERRIDE = {\n",
    "    \"training.total_updates\": 20\n",
    "}\n",
    "\n",
    "# --- helpers: load cfg, apply dot-path overrides, write temp cfg ---\n",
    "def load_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def apply_overrides(cfg: dict, overrides: dict) -> dict:\n",
    "    out = json.loads(json.dumps(cfg))  # deep copy\n",
    "    for k, v in overrides.items():\n",
    "        cur = out\n",
    "        parts = k.split(\".\")\n",
    "        for p in parts[:-1]:\n",
    "            if p not in cur or not isinstance(cur[p], dict):\n",
    "                cur[p] = {}\n",
    "            cur = cur[p]\n",
    "        cur[parts[-1]] = v\n",
    "    return out\n",
    "\n",
    "# --- compute repo root (parent of 'training' folder) and ensure import path ---\n",
    "# CFG_PATH .../training/configs/xxx.json  -> go up two levels to repo root\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname(CFG_PATH), os.pardir, os.pardir))\n",
    "print(\"Project root:\", project_root)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# --- purge any cached 'training' modules so edits are picked up ---\n",
    "to_purge = [m for m in list(sys.modules) if m == \"training\" or m.startswith(\"training.\")]\n",
    "for m in to_purge:\n",
    "    sys.modules.pop(m, None)\n",
    "importlib.invalidate_caches()\n",
    "\n",
    "# --- build merged temp config ---\n",
    "base_cfg = load_json(CFG_PATH)\n",
    "merged_cfg = apply_overrides(base_cfg, OVERRIDE)\n",
    "\n",
    "cfg_dir = os.path.dirname(CFG_PATH)\n",
    "runtime_cfg_path = os.path.join(cfg_dir, f\"_runtime_{int(time.time())}.json\")\n",
    "with open(runtime_cfg_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(merged_cfg, f, indent=2)\n",
    "print(\"Merged config written to:\", runtime_cfg_path)\n",
    "print(\"total_updates =\", merged_cfg.get(\"training\", {}).get(\"total_updates\"))\n",
    "\n",
    "# --- (optional) encourage line-buffered output in some environments ---\n",
    "try:\n",
    "    sys.stdout.reconfigure(line_buffering=True)  # Python 3.7+\n",
    "    sys.stderr.reconfigure(line_buffering=True)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# --- run the train module in-process with the merged config (no redirection) ---\n",
    "argv = [\"training.scripts.train_vec\", \"--config\", runtime_cfg_path]\n",
    "print(\"Running in-process with argv:\", argv)\n",
    "\n",
    "old_argv = list(sys.argv)\n",
    "exit_code = 0\n",
    "try:\n",
    "    sys.argv = argv\n",
    "    # All prints from training.scripts.train will appear LIVE in PyCharm's console\n",
    "    runpy.run_module(\"training.scripts.train_vec\", run_name=\"__main__\", alter_sys=True)\n",
    "except SystemExit as se:\n",
    "    exit_code = int(getattr(se, \"code\", 0) or 0)\n",
    "except Exception as e:\n",
    "    # Any exception prints directly to the console\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    exit_code = 1\n",
    "finally:\n",
    "    sys.argv = old_argv\n",
    "\n",
    "print(\"Exit code:\", exit_code)\n",
    "\n",
    "# (Optional) clean up the temp config file\n",
    "try:\n",
    "    os.remove(runtime_cfg_path)\n",
    "except Exception:\n",
    "    pass\n"
   ],
   "id": "60f48f99727326f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: E:\\sequence_game_board\\sequence_board_game\n",
      "Merged config written to: E:\\sequence_game_board\\sequence_board_game\\training\\configs\\_runtime_1756967141.json\n",
      "total_updates = 20\n",
      "Running in-process with argv: ['training.scripts.train_vec', '--config', 'E:\\\\sequence_game_board\\\\sequence_board_game\\\\training\\\\configs\\\\_runtime_1756967141.json']\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-04T04:21:58.537302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ✅ Run training.scripts.eval in-process with a merged temp config (overrides applied reliably)\n",
    "\n",
    "import os, sys, runpy, importlib, contextlib, io, json, time\n",
    "\n",
    "CFG_PATH = r\"E:\\sequence_game_board\\sequence_board_game\\training\\configs\\full-tiny-smoke.json\"\n",
    "EVAL_OVERRIDE = {\n",
    "    # Example: you can override file paths or add agent kwargs here if needed\n",
    "    \"evaluation.agent_kwargs.agents/training/ppo_lstm_agent.py.policy_path\": \"runs/smoke/full/policy_final.pt\",\n",
    "}\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def apply_overrides(cfg: dict, overrides: dict) -> dict:\n",
    "    out = json.loads(json.dumps(cfg))\n",
    "    for k, v in overrides.items():\n",
    "        cur = out\n",
    "        parts = k.split(\".\")\n",
    "        for p in parts[:-1]:\n",
    "            if p not in cur or not isinstance(cur[p], dict):\n",
    "                cur[p] = {}\n",
    "            cur = cur[p]\n",
    "        cur[parts[-1]] = v\n",
    "    return out\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname(CFG_PATH), os.pardir, os.pardir))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "to_purge = [m for m in list(sys.modules) if m == \"training\" or m.startswith(\"training.\")]\n",
    "for m in to_purge:\n",
    "    sys.modules.pop(m, None)\n",
    "importlib.invalidate_caches()\n",
    "\n",
    "base_cfg = load_json(CFG_PATH)\n",
    "merged_cfg = apply_overrides(base_cfg, EVAL_OVERRIDE)\n",
    "\n",
    "cfg_dir = os.path.dirname(CFG_PATH)\n",
    "runtime_cfg_path = os.path.join(cfg_dir, f\"_eval_runtime_{int(time.time())}.json\")\n",
    "with open(runtime_cfg_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(merged_cfg, f, indent=2)\n",
    "print(\"Merged EVAL config:\", runtime_cfg_path)\n",
    "\n",
    "argv = [\"training.scripts.eval\", \"--config\", runtime_cfg_path, \"--episodes\", \"100\"]\n",
    "\n",
    "stdout_buf, stderr_buf = io.StringIO(), io.StringIO()\n",
    "print(\"Running eval in-process with argv:\", argv)\n",
    "\n",
    "with contextlib.redirect_stdout(stdout_buf), contextlib.redirect_stderr(stderr_buf):\n",
    "    old_argv = sys.argv\n",
    "    try:\n",
    "        sys.argv = argv\n",
    "        runpy.run_module(\"training.scripts.eval\", run_name=\"__main__\", alter_sys=True)\n",
    "        exit_code = 0\n",
    "    except SystemExit as se:\n",
    "        exit_code = int(getattr(se, \"code\", 0) or 0)\n",
    "    except Exception:\n",
    "        import traceback; traceback.print_exc()\n",
    "        exit_code = 1\n",
    "    finally:\n",
    "        sys.argv = old_argv\n",
    "\n",
    "print(\"--- STDOUT (tail) ---+\\n\", stdout_buf.getvalue()[-8000:])\n",
    "print(\"--- STDERR (tail) ---\\n\", stderr_buf.getvalue()[-8000:])\n",
    "print(\"Exit code:\", exit_code)\n"
   ],
   "id": "91473a059632e7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T20:59:59.121404Z",
     "start_time": "2025-08-25T20:59:59.006660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"E:\\sequence_game_board\\sequence_board_game\\training\\runs\\smoke\\run\" --port 5907 --reload_interval 3"
   ],
   "id": "5dbd94e5bc9e49",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 5907 (pid 70272), started 21:18:08 ago. (Use '!kill 70272' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 5907;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T23:39:50.513848Z",
     "start_time": "2025-08-24T23:39:50.507477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, glob, pprint\n",
    "from tensorboard.backend.event_processing import event_accumulator as EA\n",
    "\n",
    "LOGDIR = r\"E:/sequence_game_board/sequence_board_game/runs/smoke/run/\"   # point at the parent, not the leaf\n",
    "events = glob.glob(os.path.join(LOGDIR, \"**\", \"events.out.tfevents.*\"), recursive=True)\n",
    "print(\"Found\", len(events), \"event file(s)\")\n",
    "pprint.pprint(events[-5:])\n",
    "\n",
    "if events:\n",
    "    ea = EA.EventAccumulator(os.path.dirname(events[-1]))  # load its containing directory\n",
    "    ea.Reload()\n",
    "    print(\"\\nTAGS:\", ea.Tags())        # should include 'scalars'\n",
    "    print(\"Scalar keys:\", list(ea.Scalars('loss/total')[:3]) if 'loss/total' in ea.Tags().get('scalars', []) else \"no loss/total\")\n",
    "    size = os.path.getsize(events[-1])\n",
    "    print(\"Event file size (bytes):\", size)"
   ],
   "id": "1929e3ef8e3ae446",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 event file(s)\n",
      "[]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b6da1f3f90a33841"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
