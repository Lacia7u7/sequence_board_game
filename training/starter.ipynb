{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Starter: Sequence RL — debug-friendly notebook (Anaconda base)\n",
    "\n",
    "Run the cells **in order** (1 → 10).\n",
    "This notebook:\n",
    "- uses your Anaconda base env (no venv),\n",
    "- verifies CUDA,\n",
    "- wires `sys.path` so `training/` imports,\n",
    "- runs the trainer **in-process** (easy to debug) or via subprocess,\n",
    "- starts TensorBoard,\n",
    "- evaluates a saved policy,\n",
    "- and gives quick unit-test & step-debug helpers.\n"
   ],
   "id": "c496235011770648"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T20:36:43.015438Z",
     "start_time": "2025-08-24T20:36:42.877412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, sys, subprocess, textwrap\n",
    "\n",
    "print(\"Python:\", sys.executable)\n",
    "try:\n",
    "    import torch\n",
    "    print(\"PyTorch:\", torch.__version__)\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    print(\"CUDA version:\", getattr(torch.version, \"cuda\", None))\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "        print(\"Device 0:\", torch.cuda.get_device_name(0))\n",
    "except Exception as e:\n",
    "    print(\"Torch import error:\", e)\n",
    "\n",
    "# Optional: show nvidia-smi (won't crash if missing)\n",
    "try:\n",
    "    print(\"\\n--- nvidia-smi ---\")\n",
    "    out = subprocess.run([\"nvidia-smi\"], capture_output=True, text=True)\n",
    "    print(out.stdout or out.stderr)\n",
    "except Exception as e:\n",
    "    print(\"nvidia-smi not available:\", e)\n"
   ],
   "id": "a41da3316c0ab59a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: C:\\Users\\carlo\\anaconda3\\python.exe\n",
      "PyTorch: 2.2.1\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "CUDA device count: 1\n",
      "Device 0: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "\n",
      "--- nvidia-smi ---\n",
      "Sun Aug 24 14:36:42 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 551.61                 Driver Version: 551.61         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   56C    P8              4W /   25W |     376MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      6032    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     12208    C+G   ...ZWMJ2QHF7EXQJXRPE6GR5GOTQ\\DeepL.exe      N/A      |\n",
      "|    0   N/A  N/A     19980    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A     31236    C+G   ...n\\139.0.3405.102\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     32760    C+G   ...by Google One\\1.9.0.6\\googleone.exe      N/A      |\n",
      "|    0   N/A  N/A     36284    C+G   ...n\\139.0.3405.102\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     38804    C+G   ...cw5n1h2txyewy\\CrossDeviceResume.exe      N/A      |\n",
      "|    0   N/A  N/A     40520    C+G   ...3.0_x64__cv1g1gvanyjgm\\WhatsApp.exe      N/A      |\n",
      "|    0   N/A  N/A     41552    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     41608    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     42704    C+G   ...m 2025.2.0.1\\jbr\\bin\\cef_server.exe      N/A      |\n",
      "|    0   N/A  N/A     50512    C+G   ...3\\extracted\\runtime\\WeChatAppEx.exe      N/A      |\n",
      "|    0   N/A  N/A     59120    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     59948    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     61132    C+G   ...n\\139.0.3405.102\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     61472    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     61892    C+G   ...Desktop\\app-3.5.2\\GitHubDesktop.exe      N/A      |\n",
      "|    0   N/A  N/A     65220    C+G   ...n\\139.0.3405.111\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     67228    C+G   C:\\Windows\\System32\\ShellHost.exe           N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T21:15:28.670582Z",
     "start_time": "2025-08-24T21:11:53.655251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, sys, runpy, importlib, contextlib, io, json\n",
    "\n",
    "# --- configure your paths/overrides ---\n",
    "CFG_PATH = r\"E:\\sequence_game_board\\sequence_board_game\\training\\configs\\tiny-smoke.json\"\n",
    "OVERRIDE = {\n",
    "    \"training.num_envs\": 8, \"training.rollout_length\": 32, \"training.total_updates\": 200, \"training.minibatch_size\": 512,\n",
    "    \"logging.tensorboard\": True\n",
    "}\n",
    "\n",
    "# Project root = repo folder that contains the 'training' package\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname(CFG_PATH), os.pardir))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(\"Project root:\", project_root)\n",
    "\n",
    "# --- nuke any cached 'training' modules so we load the edited code ---\n",
    "to_purge = [m for m in list(sys.modules) if m == \"training\" or m.startswith(\"training.\")]\n",
    "for m in to_purge:\n",
    "    del sys.modules[m]\n",
    "importlib.invalidate_caches()\n",
    "\n",
    "# Sanity: import the state module we will actually use\n",
    "import training\n",
    "import training.engine.state as st\n",
    "print(\"training package file:\", training.__file__)\n",
    "print(\"state.py path        :\", st.__file__)\n",
    "print(\"has sequences_meta_cells?:\", hasattr(st.GameState, \"sequences_meta_cells\"))\n",
    "assert hasattr(st.GameState, \"sequences_meta_cells\"), \"Your edited GameState isn't loading!\"\n",
    "\n",
    "# --- run the script in-process with a clean argv ---\n",
    "argv = [\n",
    "    \"training.scripts.train\",\n",
    "    \"--config\", CFG_PATH,\n",
    "    \"--override\", json.dumps(OVERRIDE),\n",
    "]\n",
    "\n",
    "stdout_buf, stderr_buf = io.StringIO(), io.StringIO()\n",
    "print(\"Running in-process with argv:\", argv)\n",
    "\n",
    "with contextlib.redirect_stdout(stdout_buf), contextlib.redirect_stderr(stderr_buf):\n",
    "    old_argv = sys.argv\n",
    "    try:\n",
    "        sys.argv = argv\n",
    "        # alter_sys=True helps mimic \"python -m\"\n",
    "        runpy.run_module(\"training.scripts.train\", run_name=\"__main__\", alter_sys=True)\n",
    "        exit_code = 0\n",
    "    except SystemExit as se:\n",
    "        exit_code = int(getattr(se, \"code\", 0) or 0)\n",
    "    except Exception as e:\n",
    "        exit_code = 1\n",
    "        print(\"EXCEPTION:\", repr(e))\n",
    "    finally:\n",
    "        sys.argv = old_argv\n",
    "\n",
    "out, err = stdout_buf.getvalue(), stderr_buf.getvalue()\n",
    "print(\"--- STDOUT ---\\n\", out[-10000:])\n",
    "print(\"--- STDERR ---\\n\", err[-10000:])\n",
    "print(\"Exit code:\", exit_code)\n"
   ],
   "id": "8228756e6c62d23b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: E:\\sequence_game_board\\sequence_board_game\\training\n",
      "training package file: E:\\sequence_game_board\\sequence_board_game\\training\\__init__.py\n",
      "state.py path        : E:\\sequence_game_board\\sequence_board_game\\training\\engine\\state.py\n",
      "has sequences_meta_cells?: True\n",
      "Running in-process with argv: ['training.scripts.train', '--config', 'E:\\\\sequence_game_board\\\\sequence_board_game\\\\training\\\\configs\\\\tiny-smoke.json', '--override', '{\"training.num_envs\": 8, \"training.rollout_length\": 32, \"training.total_updates\": 200, \"training.minibatch_size\": 512, \"logging.tensorboard\": true}']\n",
      "--- STDOUT ---\n",
      " .0000 | loss/entropy:4.6456\n",
      "update 112/200 | loss/total:56191944.0000 | loss/policy:0.2072 | loss/value:112383888.0000 | loss/entropy:4.6457\n",
      "update 113/200 | loss/total:13797958.0000 | loss/policy:0.2074 | loss/value:27595916.0000 | loss/entropy:4.6458\n",
      "update 114/200 | loss/total:31464174.0000 | loss/policy:0.2075 | loss/value:62928348.0000 | loss/entropy:4.6458\n",
      "update 115/200 | loss/total:65425348.0000 | loss/policy:0.2075 | loss/value:130850696.0000 | loss/entropy:4.6459\n",
      "update 116/200 | loss/total:19257962.0000 | loss/policy:0.2075 | loss/value:38515924.0000 | loss/entropy:4.6460\n",
      "update 117/200 | loss/total:23564742.0000 | loss/policy:0.2073 | loss/value:47129484.0000 | loss/entropy:4.6461\n",
      "update 118/200 | loss/total:52571928.0000 | loss/policy:0.2074 | loss/value:105143856.0000 | loss/entropy:4.6462\n",
      "update 119/200 | loss/total:12066750.0000 | loss/policy:0.2073 | loss/value:24133500.0000 | loss/entropy:4.6463\n",
      "update 120/200 | loss/total:34188912.0000 | loss/policy:0.2071 | loss/value:68377824.0000 | loss/entropy:4.6464\n",
      "update 121/200 | loss/total:69331176.0000 | loss/policy:0.2073 | loss/value:138662352.0000 | loss/entropy:4.6465\n",
      "update 122/200 | loss/total:21336442.0000 | loss/policy:0.2072 | loss/value:42672884.0000 | loss/entropy:4.6465\n",
      "update 123/200 | loss/total:21371804.0000 | loss/policy:0.2073 | loss/value:42743608.0000 | loss/entropy:4.6466\n",
      "update 124/200 | loss/total:49383952.0000 | loss/policy:0.2073 | loss/value:98767904.0000 | loss/entropy:4.6467\n",
      "update 125/200 | loss/total:10514398.0000 | loss/policy:0.2073 | loss/value:21028796.0000 | loss/entropy:4.6467\n",
      "update 126/200 | loss/total:36970652.0000 | loss/policy:0.2071 | loss/value:73941304.0000 | loss/entropy:4.6468\n",
      "update 127/200 | loss/total:72754408.0000 | loss/policy:0.2074 | loss/value:145508816.0000 | loss/entropy:4.6469\n",
      "update 128/200 | loss/total:23392648.0000 | loss/policy:0.2072 | loss/value:46785296.0000 | loss/entropy:4.6469\n",
      "update 129/200 | loss/total:19441956.0000 | loss/policy:0.2074 | loss/value:38883912.0000 | loss/entropy:4.6470\n",
      "update 130/200 | loss/total:46335508.0000 | loss/policy:0.2074 | loss/value:92671016.0000 | loss/entropy:4.6470\n",
      "update 131/200 | loss/total:9214703.0000 | loss/policy:0.2073 | loss/value:18429406.0000 | loss/entropy:4.6471\n",
      "update 132/200 | loss/total:39454628.0000 | loss/policy:0.2071 | loss/value:78909256.0000 | loss/entropy:4.6472\n",
      "update 133/200 | loss/total:76501480.0000 | loss/policy:0.2075 | loss/value:153002960.0000 | loss/entropy:4.6472\n",
      "update 134/200 | loss/total:25439434.0000 | loss/policy:0.2072 | loss/value:50878868.0000 | loss/entropy:4.6473\n",
      "update 135/200 | loss/total:17728124.0000 | loss/policy:0.2074 | loss/value:35456248.0000 | loss/entropy:4.6473\n",
      "update 136/200 | loss/total:43778096.0000 | loss/policy:0.2073 | loss/value:87556192.0000 | loss/entropy:4.6474\n",
      "update 137/200 | loss/total:8132695.5000 | loss/policy:0.2074 | loss/value:16265391.0000 | loss/entropy:4.6474\n",
      "update 138/200 | loss/total:41922772.0000 | loss/policy:0.2067 | loss/value:83845544.0000 | loss/entropy:4.6475\n",
      "update 139/200 | loss/total:79634536.0000 | loss/policy:0.2074 | loss/value:159269072.0000 | loss/entropy:4.6476\n",
      "update 140/200 | loss/total:27271176.0000 | loss/policy:0.2075 | loss/value:54542352.0000 | loss/entropy:4.6476\n",
      "update 141/200 | loss/total:16171973.0000 | loss/policy:0.2072 | loss/value:32343946.0000 | loss/entropy:4.6477\n",
      "update 142/200 | loss/total:41261188.0000 | loss/policy:0.2074 | loss/value:82522376.0000 | loss/entropy:4.6477\n",
      "update 143/200 | loss/total:7067160.0000 | loss/policy:0.2073 | loss/value:14134320.0000 | loss/entropy:4.6478\n",
      "update 144/200 | loss/total:44131352.0000 | loss/policy:0.2072 | loss/value:88262704.0000 | loss/entropy:4.6478\n",
      "update 145/200 | loss/total:82885760.0000 | loss/policy:0.2074 | loss/value:165771520.0000 | loss/entropy:4.6479\n",
      "update 146/200 | loss/total:29002112.0000 | loss/policy:0.2072 | loss/value:58004224.0000 | loss/entropy:4.6479\n",
      "update 147/200 | loss/total:14842797.0000 | loss/policy:0.2073 | loss/value:29685594.0000 | loss/entropy:4.6480\n",
      "update 148/200 | loss/total:38986112.0000 | loss/policy:0.2073 | loss/value:77972224.0000 | loss/entropy:4.6480\n",
      "update 149/200 | loss/total:6228028.0000 | loss/policy:0.2073 | loss/value:12456056.0000 | loss/entropy:4.6481\n",
      "update 150/200 | loss/total:46267932.0000 | loss/policy:0.2071 | loss/value:92535864.0000 | loss/entropy:4.6481\n",
      "update 151/200 | loss/total:85776752.0000 | loss/policy:0.2072 | loss/value:171553504.0000 | loss/entropy:4.6482\n",
      "update 152/200 | loss/total:30842252.0000 | loss/policy:0.2071 | loss/value:61684504.0000 | loss/entropy:4.6482\n",
      "update 153/200 | loss/total:13606628.0000 | loss/policy:0.2072 | loss/value:27213256.0000 | loss/entropy:4.6482\n",
      "update 154/200 | loss/total:37069960.0000 | loss/policy:0.2074 | loss/value:74139920.0000 | loss/entropy:4.6483\n",
      "update 155/200 | loss/total:5505485.0000 | loss/policy:0.2073 | loss/value:11010970.0000 | loss/entropy:4.6483\n",
      "update 156/200 | loss/total:48471300.0000 | loss/policy:0.2073 | loss/value:96942600.0000 | loss/entropy:4.6483\n",
      "update 157/200 | loss/total:88597680.0000 | loss/policy:0.2075 | loss/value:177195360.0000 | loss/entropy:4.6484\n",
      "update 158/200 | loss/total:32536204.0000 | loss/policy:0.2071 | loss/value:65072408.0000 | loss/entropy:4.6484\n",
      "update 159/200 | loss/total:12586520.0000 | loss/policy:0.2073 | loss/value:25173040.0000 | loss/entropy:4.6485\n",
      "update 160/200 | loss/total:35400476.0000 | loss/policy:0.2072 | loss/value:70800952.0000 | loss/entropy:4.6485\n",
      "update 161/200 | loss/total:4813590.0000 | loss/policy:0.2074 | loss/value:9627180.0000 | loss/entropy:4.6485\n",
      "update 162/200 | loss/total:50252232.0000 | loss/policy:0.2070 | loss/value:100504464.0000 | loss/entropy:4.6486\n",
      "update 163/200 | loss/total:91423936.0000 | loss/policy:0.2071 | loss/value:182847872.0000 | loss/entropy:4.6486\n",
      "update 164/200 | loss/total:34090632.0000 | loss/policy:0.2072 | loss/value:68181264.0000 | loss/entropy:4.6487\n",
      "update 165/200 | loss/total:11608926.0000 | loss/policy:0.2072 | loss/value:23217852.0000 | loss/entropy:4.6487\n",
      "update 166/200 | loss/total:33821496.0000 | loss/policy:0.2074 | loss/value:67642992.0000 | loss/entropy:4.6487\n",
      "update 167/200 | loss/total:4272052.0000 | loss/policy:0.2074 | loss/value:8544104.0000 | loss/entropy:4.6487\n",
      "update 168/200 | loss/total:52272748.0000 | loss/policy:0.2073 | loss/value:104545496.0000 | loss/entropy:4.6488\n",
      "update 169/200 | loss/total:93648792.0000 | loss/policy:0.2075 | loss/value:187297584.0000 | loss/entropy:4.6488\n",
      "update 170/200 | loss/total:35568280.0000 | loss/policy:0.2074 | loss/value:71136560.0000 | loss/entropy:4.6489\n",
      "update 171/200 | loss/total:10771106.0000 | loss/policy:0.2073 | loss/value:21542212.0000 | loss/entropy:4.6489\n",
      "update 172/200 | loss/total:32475220.0000 | loss/policy:0.2073 | loss/value:64950440.0000 | loss/entropy:4.6490\n",
      "update 173/200 | loss/total:3785214.5000 | loss/policy:0.2074 | loss/value:7570428.5000 | loss/entropy:4.6490\n",
      "update 174/200 | loss/total:53847912.0000 | loss/policy:0.2073 | loss/value:107695824.0000 | loss/entropy:4.6491\n",
      "update 175/200 | loss/total:96031712.0000 | loss/policy:0.2074 | loss/value:192063424.0000 | loss/entropy:4.6492\n",
      "update 176/200 | loss/total:37058784.0000 | loss/policy:0.2075 | loss/value:74117568.0000 | loss/entropy:4.6492\n",
      "update 177/200 | loss/total:10018081.0000 | loss/policy:0.2073 | loss/value:20036162.0000 | loss/entropy:4.6493\n",
      "update 178/200 | loss/total:31053186.0000 | loss/policy:0.2072 | loss/value:62106372.0000 | loss/entropy:4.6494\n",
      "update 179/200 | loss/total:3370872.0000 | loss/policy:0.2074 | loss/value:6741743.5000 | loss/entropy:4.6494\n",
      "update 180/200 | loss/total:55415260.0000 | loss/policy:0.2075 | loss/value:110830520.0000 | loss/entropy:4.6495\n",
      "update 181/200 | loss/total:98009608.0000 | loss/policy:0.2073 | loss/value:196019216.0000 | loss/entropy:4.6495\n",
      "update 182/200 | loss/total:38308232.0000 | loss/policy:0.2073 | loss/value:76616464.0000 | loss/entropy:4.6496\n",
      "update 183/200 | loss/total:9371269.0000 | loss/policy:0.2073 | loss/value:18742538.0000 | loss/entropy:4.6497\n",
      "update 184/200 | loss/total:30078590.0000 | loss/policy:0.2074 | loss/value:60157180.0000 | loss/entropy:4.6497\n",
      "update 185/200 | loss/total:2989958.0000 | loss/policy:0.2073 | loss/value:5979915.5000 | loss/entropy:4.6498\n",
      "update 186/200 | loss/total:57026116.0000 | loss/policy:0.2076 | loss/value:114052232.0000 | loss/entropy:4.6498\n",
      "update 187/200 | loss/total:99983808.0000 | loss/policy:0.2068 | loss/value:199967616.0000 | loss/entropy:4.6499\n",
      "update 188/200 | loss/total:39436260.0000 | loss/policy:0.2072 | loss/value:78872520.0000 | loss/entropy:4.6500\n",
      "update 189/200 | loss/total:8796683.0000 | loss/policy:0.2072 | loss/value:17593366.0000 | loss/entropy:4.6500\n",
      "update 190/200 | loss/total:28961590.0000 | loss/policy:0.2073 | loss/value:57923180.0000 | loss/entropy:4.6500\n",
      "update 191/200 | loss/total:2689808.2500 | loss/policy:0.2073 | loss/value:5379616.0000 | loss/entropy:4.6501\n",
      "update 192/200 | loss/total:58308760.0000 | loss/policy:0.2075 | loss/value:116617520.0000 | loss/entropy:4.6501\n",
      "update 193/200 | loss/total:101566584.0000 | loss/policy:0.2073 | loss/value:203133168.0000 | loss/entropy:4.6501\n",
      "update 194/200 | loss/total:40421548.0000 | loss/policy:0.2074 | loss/value:80843096.0000 | loss/entropy:4.6502\n",
      "update 195/200 | loss/total:8302384.5000 | loss/policy:0.2073 | loss/value:16604769.0000 | loss/entropy:4.6502\n",
      "update 196/200 | loss/total:28092312.0000 | loss/policy:0.2073 | loss/value:56184624.0000 | loss/entropy:4.6502\n",
      "update 197/200 | loss/total:2407219.5000 | loss/policy:0.2074 | loss/value:4814438.5000 | loss/entropy:4.6502\n",
      "update 198/200 | loss/total:59450776.0000 | loss/policy:0.2073 | loss/value:118901552.0000 | loss/entropy:4.6503\n",
      "update 199/200 | loss/total:103264232.0000 | loss/policy:0.2072 | loss/value:206528464.0000 | loss/entropy:4.6503\n",
      "update 200/200 | loss/total:41581660.0000 | loss/policy:0.2073 | loss/value:83163320.0000 | loss/entropy:4.6504\n",
      "\n",
      "--- STDERR ---\n",
      " \n",
      "Exit code: 0\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T21:11:07.051252Z",
     "start_time": "2025-08-24T21:11:06.885382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"E:/sequence_game_board/sequence_board_game/runs\" --port 6007 --reload_interval 3"
   ],
   "id": "5dbd94e5bc9e49",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 67004), started 0:06:34 ago. (Use '!kill 67004' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a713c1e0fb51262b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a713c1e0fb51262b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T21:15:28.921700Z",
     "start_time": "2025-08-24T21:15:28.701620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import glob\n",
    "paths = glob.glob(r\"E:\\sequence_game_board\\sequence_board_game\\runs\\**\\events.*\", recursive=True)\n",
    "print(\"Found:\", len(paths))\n",
    "for p in paths[:10]:\n",
    "    print(\" \", p)\n"
   ],
   "id": "1929e3ef8e3ae446",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 0\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b6da1f3f90a33841"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
